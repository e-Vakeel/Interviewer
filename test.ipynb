{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ANTHROPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY')\n",
    "print(ANTHROPIC_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import anthropic\n",
    "# import requests\n",
    "# import bs4\n",
    "# from rich import print\n",
    "# import time\n",
    "\n",
    "# client = anthropic.Client(ANTHROPIC_API_KEY)\n",
    "\n",
    "# response = client.beta.prompt_caching.messages.create(\n",
    "#  model=\"claude-3-haiku-2024-03-07\",\n",
    "#  max_tokens=1024,\n",
    "#  system=[\n",
    "#   {\n",
    "#    type=\"text\",\n",
    "#    text=\"Act as our Operating System and DBMS teacher and answer the following questions:\",\n",
    "#   }\n",
    "#  ])\n",
    "##no point in using this as the cache lifetime is only 5 minutes when unused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "#from vertexai.generative_models import GenerationConfig, GenerativeModel\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "from vertexai.preview import caching\n",
    "\n",
    "from vertexai.generative_models import Part\n",
    "from vertexai.preview import caching\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "project_id = \"sascha-playground-doit\"\n",
    "vertexai.init(project=project_id, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def measure_time():\n",
    "    start_time = time.perf_counter()\n",
    "    yield\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without using cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"\n",
    "You are an expert book reader, and you answer user's query based on the book you have access to.\n",
    "\"\"\"\n",
    "\n",
    "video = Part.from_uri(\n",
    "    mime_type=\"application/pdf\",\n",
    "    uri=\"./books/OS.pdf\",)\n",
    "\n",
    "model = GenerativeModel(\n",
    "    \"gemini-1.5-pro-001\",\n",
    "    system_instruction=[system_instruction]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with measure_time():\n",
    "  response = model.generate_content(\n",
    "      [video, \"\"\"What is the difference between a process and a thread?\"\"\"],\n",
    "  )\n",
    "  print(response.usage_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"\n",
    "You are an expert video analyzer, and you answer user's query based on the video file you have access to.\n",
    "\"\"\"\n",
    "\n",
    "contents = [\n",
    "    Part.from_uri(\n",
    "    mime_type=\"video/mp4\",\n",
    "    uri=\"gs://doit-ml-demo/gemini/caching/video/Getting started with Gemini on Vertex AI.mp4\")\n",
    "]\n",
    "\n",
    "cached_content = caching.CachedContent.create(\n",
    "    model_name=\"gemini-1.5-pro-001\",\n",
    "    #model_name=\"gemini-1.5-flash-001\",\n",
    "    system_instruction=system_instruction,\n",
    "    contents=contents,\n",
    "    ttl=datetime.timedelta(minutes=60),\n",
    ")\n",
    "\n",
    "cache_name = cached_content.name\n",
    "print(cache_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_content = caching.CachedContent(cached_content_name=cache_name)\n",
    "cached_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = GenerativeModel.from_cached_content(cached_content=cached_content)\n",
    "response = model.generate_content(\"provide a summary for the video\")\n",
    "print(response.usage_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using Anthropic API for CN and OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "# Create an instance of the Anthropics API client\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)  \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_claude(query):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1024,\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "        system=\"You are an expert in computer networks and Object Oriented Programming, and you answer user's multiple choice questions based on your knowledge. Keep your answers concise mentioning only the option that you think is the correct answer , don't mention the reason and answer with at most 10 words.\",\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ask_claude(\" A proxy server is used as the computer? the options are  external access acting as a backup performing file handling accessing user permissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
